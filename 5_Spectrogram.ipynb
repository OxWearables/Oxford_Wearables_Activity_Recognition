{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Training on the spectrogram of the signal\n","\n","Computing the [spectrogram](https://en.wikipedia.org/wiki/Spectrogram) of a\n","signal is a common visualization method in signal processing to treat\n","signals as 2D images. Recent works have looked at using the spectrogram\n","for classification, thus converting the signal recognition task into an image\n","recognition one and leveraging techniques from computer vision.\n","\n","## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import scipy.signal\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torch.backends.cudnn as cudnn\n","from sklearn import metrics\n","from sklearn.preprocessing import LabelEncoder\n","from tqdm.auto import tqdm\n","\n","import utils\n","\n","# For reproducibility\n","np.random.seed(42)\n","torch.manual_seed(42)\n","cudnn.benchmark = True\n","\n","# Grab a GPU if there is one\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(\"Using {} device: {}\".format(device, torch.cuda.current_device()))\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"Using {}\".format(device))"]},{"cell_type":"markdown","metadata":{},"source":["## Load dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Path to your extracted windows\n","DATASET_PATH = 'processed_data/'\n","print(f'Content of {DATASET_PATH}')\n","print(os.listdir(DATASET_PATH))\n","\n","X = np.load(DATASET_PATH+'X.npy', mmap_mode='r')\n","Y = np.load(DATASET_PATH+'Y.npy')\n","T = np.load(DATASET_PATH+'T.npy')\n","pid = np.load(DATASET_PATH+'pid.npy')\n","\n","# As before, let's map the text annotations to simplified labels\n","ANNO_LABEL_DICT_PATH = 'capture24/annotation-label-dictionary.csv'\n","anno_label_dict = pd.read_csv(ANNO_LABEL_DICT_PATH, index_col='annotation', dtype='string')\n","Y = anno_label_dict.loc[Y, 'label:Willetts2018'].to_numpy()\n","\n","# Transform to numeric\n","le = LabelEncoder().fit(Y)\n","Y = le.transform(Y)"]},{"cell_type":"markdown","metadata":{},"source":["## Train/test split"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Hold out participants P101-P151 for testing (51 participants)\n","test_ids = [f'P{i}' for i in range(101,152)]\n","mask_test = np.isin(pid, test_ids)\n","mask_train = ~mask_test\n","X_train, Y_train, T_train, pid_train = \\\n","    X[mask_train], Y[mask_train], T[mask_train], pid[mask_train]\n","X_test, Y_test, T_test, pid_test = \\\n","    X[mask_test], Y[mask_test], T[mask_test], pid[mask_test]\n","print(\"Shape of X_train:\", X_train.shape)\n","print(\"Shape of X_test:\", X_test.shape)"]},{"cell_type":"markdown","metadata":{},"source":[" ## Visualization\n","\n","Let's visualize the spectrograms of the acceleration norm for each activity class.\n","We use\n","[scipy.signal.stft](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.stft.html).\n","Here, the arguments `nperseg` and `noverlap` determine the size of the\n","resulting spectrogram. For `nperseg=120` and `noverlap=72`, the spectrogram\n","size is $61\\times 61$.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Spectrogram parameters\n","N_FFT = 120\n","HOP_LENGTH = 48\n","WINDOW = 'hann'\n","NUM_PLOTS = 10\n","\n","labels = np.unique(Y_train)\n","num_labels = len(labels)\n","\n","fig, axs = plt.subplots(num_labels, NUM_PLOTS, figsize=(16,8))\n","fig.patch.set_facecolor('white')\n","for i in range(num_labels):\n","    axs[i,0].set_ylabel(le.inverse_transform([labels[i]]).item())\n","    idxs = np.where(Y_train==i)[0]\n","    for j in range(NUM_PLOTS):\n","        _, _, z = scipy.signal.stft(\n","            np.linalg.norm(X_train[idxs[j]], axis=1),  # acceleration vector norm\n","            nperseg=N_FFT,\n","            noverlap=N_FFT-HOP_LENGTH,\n","            window=WINDOW,\n","            boundary=None, padded=False\n","        )\n","        z = np.log(np.abs(z) + 1e-16)\n","        axs[i,j].imshow(z, cmap='coolwarm')\n","        axs[i,j].set_xticks([])\n","        axs[i,j].set_yticks([])"]},{"cell_type":"markdown","metadata":{},"source":["**Exercise 1**: Inspect the example spectograms for each label produced by the code above. Which labels look most distinct and most similar? Is this what you expected, given what you know about these tasks, and how the models produced in previous notebooks have performed?"]},{"cell_type":"markdown","metadata":{},"source":["**Exercise 2**: The code above provides visualisations for spectrograms for the first 10 examples of the label class. Adjust this code below to instead produce spectrograms from 10 random selections for each label class. Why would this be a useful thing to do?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Architecture design\n","\n","As a baseline, let's use a convolutional neural network (CNN) with a typical\n","pyramid-like structure. The input to the network is a `(N,3,61,61)` array,\n","corresponding to `N` spectrograms for each axis signal. Again, note the\n","*channels-first* format: `(3,61,61)` instead of `(61,61,3)`.\n","\n","The output of the CNN is a `(N,num_labels)` array where each row contains\n","predicted unnormalized class scores or *logits*; pass each row to a softmax\n","if you want to convert it to probabilities.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ConvBNReLU(nn.Module):\n","    ''' Convolution + batch normalization + ReLU is a common trio '''\n","    def __init__(\n","        self, in_channels, out_channels,\n","        kernel_size=3, stride=1, padding=1, bias=True\n","    ):\n","        super(ConvBNReLU, self).__init__()\n","\n","        self.main = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels,\n","                kernel_size, stride, padding, bias=bias),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(True)\n","        )\n","\n","    def forward(self, x):\n","        return self.main(x)\n","\n","class CNN(nn.Module):\n","    ''' Typical CNN design with pyramid-like structure '''\n","    def __init__(self, output_size=5, in_channels=3, num_filters_init=8):\n","        super(CNN, self).__init__()\n","\n","        self.cnn = nn.Sequential(\n","            ConvBNReLU(in_channels, num_filters_init,\n","            3, 2, 1, bias=False),  # 61x61 -> 31x31\n","            ConvBNReLU(num_filters_init, num_filters_init*2,\n","            3, 2, 1, bias=False),  # 31x31 -> 16x16\n","            ConvBNReLU(num_filters_init*2, num_filters_init*4,\n","            4, 2, 1, bias=False),  # 16x16 -> 8x8\n","            ConvBNReLU(num_filters_init*4, num_filters_init*8,\n","            4, 2, 1, bias=False),  # 8x8 -> 4x4\n","            ConvBNReLU(num_filters_init*8, num_filters_init*16,\n","            4, 1, 0, bias=False),  # 4x4 -> 1x1\n","            nn.Conv2d(num_filters_init*16, output_size,\n","            1, 1, 0, bias=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.cnn(x).view(x.shape[0],-1)"]},{"cell_type":"markdown","metadata":{},"source":["## Helper functions\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_dataloader(X, y=None, batch_size=1, shuffle=False):\n","    ''' Create a (batch) iterator over the dataset.\n","    Alternatively, use PyTorch's Dataset and DataLoader classes.\n","    See https://pytorch.org/tutorials/beginner/data_loading_tutorial.html '''\n","\n","    # Spectrogram parameters\n","    N_FFT = 120\n","    HOP_LENGTH = 48\n","    WINDOW = torch.hann_window(N_FFT)\n","\n","    if shuffle:\n","        idxs = np.random.permutation(np.arange(len(X)))\n","    else:\n","        idxs = np.arange(len(X))\n","    for i in range(0, len(idxs), batch_size):\n","        idxs_batch = idxs[i:i+batch_size]\n","        X_batch = X[idxs_batch].astype('f4')  # PyTorch defaults to float32\n","        X_batch = np.transpose(X_batch, (0,2,1))  # channels first: (N,M,3) -> (N,3,M)\n","        X_batch = torch.from_numpy(X_batch)\n","        Z_batch = torch.stft(\n","            # Pack channel and batch dimensions.\n","            # Also upload the batch to GPU to compute the STFT.\n","            # Let the GPU do the work -- Gordon Ramsey\n","            X_batch.reshape(-1, X_batch.shape[-1]).to(device),\n","            n_fft=N_FFT,\n","            hop_length=HOP_LENGTH,\n","            window=WINDOW.to(device),\n","            center=False,\n","            return_complex=False\n","        )\n","        # Unpack channel and batch dimensions\n","        Z_batch = Z_batch.view(*X_batch.shape[:2], *Z_batch.shape[1:])\n","        Z_batch = torch.log(torch.norm(Z_batch, dim=-1) + 1e-16)\n","        if y is None:\n","            yield Z_batch\n","        else:\n","            y_batch = torch.from_numpy(y[idxs_batch])\n","            y_batch = y_batch.to(device)  # upload to GPU for consistency\n","            yield Z_batch, y_batch\n","\n","\n","def forward_by_batches(cnn, X):\n","    ''' Forward pass model on a dataset.\n","    Do this by batches so that we don't blow up the memory. '''\n","    Y = []\n","    cnn.eval()\n","    with torch.no_grad():\n","        for z in create_dataloader(X, batch_size=1024, shuffle=False):  # do not shuffle here!\n","            z = z.to(device)\n","            Y.append(cnn(z))\n","    cnn.train()\n","    Y = torch.cat(Y)\n","    return Y\n","\n","\n","def evaluate_model(cnn, X, Y):\n","    Y_pred = forward_by_batches(cnn, X)  # scores\n","    loss = F.cross_entropy(Y_pred, torch.from_numpy(Y).type(torch.int64).to(device)).item()\n","\n","    Y_pred = F.softmax(Y_pred, dim=1)  # convert to probabilities\n","    Y_pred = torch.argmax(Y_pred, dim=1)  # convert to classes\n","    Y_pred = Y_pred.cpu().numpy()  # cast to numpy array\n","    kappa = metrics.cohen_kappa_score(Y, Y_pred)\n","\n","    return {'loss':loss, 'kappa':kappa, 'Y_pred':Y_pred}"]},{"cell_type":"markdown","metadata":{},"source":["## Hyperparameters, model instantiation, loss function and optimizer\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_filters_init = 32  # initial num of filters -- see class definition\n","in_channels = 3  # num channels of the signal -- equal to 3 for our raw triaxial timeseries\n","output_size = num_labels  # number of classes (sleep, sedentary, etc...)\n","num_epoch = 5  # num of epochs (full loops though the training set)\n","lr = 3e-4  # learning rate\n","batch_size = 32  # size of the mini-batch\n","\n","cnn = CNN(\n","    output_size=output_size,\n","    in_channels=in_channels,\n","    num_filters_init=num_filters_init\n",").to(device)\n","print(cnn)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(cnn.parameters(), lr=lr)"]},{"cell_type":"markdown","metadata":{},"source":["## Training\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["kappa_history_test = []\n","loss_history_test = []\n","loss_history_train = []\n","for i in tqdm(range(num_epoch)):\n","    dataloader = create_dataloader(X_train, Y_train, batch_size, shuffle=True)\n","    losses = []\n","    for z, target in dataloader:\n","        z, target = z.to(device), target.type(torch.int64).to(device)\n","        cnn.zero_grad()\n","        output = cnn(z)\n","        loss = loss_fn(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Logging -- track train loss\n","        losses.append(loss.item())\n","\n","    # --------------------------------------------------------\n","    #       Evaluate performance at the end of each epoch\n","    # --------------------------------------------------------\n","\n","    # Logging -- average train loss in this epoch\n","    loss_history_train.append(utils.ewm(losses))\n","\n","    # Logging -- evalutate performance on test set\n","    results = evaluate_model(cnn, X_test, Y_test)\n","    loss_history_test.append(results['loss'])\n","    kappa_history_test.append(results['kappa'])"]},{"cell_type":"markdown","metadata":{},"source":[" ## Model performane "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Loss history\n","plt.close('all')\n","fig, ax = plt.subplots()\n","ax.plot(loss_history_train, color='C0', label='train loss')\n","ax.plot(loss_history_test, color='C1', label='test loss')\n","ax.set_ylabel('loss (CE)')\n","ax.set_xlabel('epoch')\n","ax = ax.twinx()\n","ax.plot(kappa_history_test, color='C2', label='kappa')\n","ax.set_ylabel('kappa')\n","ax.grid(True)\n","fig.legend()\n","\n","# Report\n","Y_test_pred_lab = le.inverse_transform(results['Y_pred'])  # back to text labels\n","Y_test_lab = le.inverse_transform(Y_test)  # back to text labels\n","print('\\nClassifier performance')\n","print('Out of sample:\\n', metrics.classification_report(Y_test_lab, Y_test_pred_lab))"]},{"cell_type":"markdown","metadata":{},"source":["**Exercise 3**: Try improving the performance of the model. Here are some things to try:\n","- Regularization. Early stopping.\n","- Architecture design, optimizer, etc."]},{"cell_type":"markdown","metadata":{},"source":["**Exercise 4**: Of all the models that you have tried in this series of notebooks, which performed the best? Why do you think that is?"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 ('wearables_workshop')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"ba62a1b4a2d59cbe868c83bdd535aa95e1f6d51e6a8dbfe9705911f17ded0148"}}},"nbformat":4,"nbformat_minor":2}
