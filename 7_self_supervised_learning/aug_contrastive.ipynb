{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "556a4897",
   "metadata": {},
   "source": [
    "# SSL learning\n",
    "Learning useful representations through recognising augmentations and matching augmented views"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ead3f1",
   "metadata": {},
   "source": [
    "# Part 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f52d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import utils.ssl_utils as ssl\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass, fields\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score, accuracy_score\n",
    "from typing import List, Tuple, Optional, Dict, Any\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaadbf71",
   "metadata": {},
   "source": [
    "## Loading data and exploring augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2cb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare capture24 data and split into train, val and test splits\n",
    "dm = ssl.Capture24DataManager(srv_root=\"/srv\", local_root=\"..\")\n",
    "ssl.set_seed(42)\n",
    "dm.prepare() # checks everything is downloaded\n",
    "(\n",
    "    x_tr, y_tr, pid_tr, # x_tr: accel segements, y_tr: labels, pid_tr: participant ID\n",
    "    x_val, y_val, pid_val, \n",
    "    x_te, y_te, pid_te,\n",
    "    le # label encoder - maps from integer labels to strings\n",
    ") = dm.train_val_test_split(prop=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b7210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AugmentConfig:\n",
    "    jitter: float = 0.5\n",
    "    scaling: float = 0.5\n",
    "    time_flip: float = 0.5\n",
    "    axis_swap: float = 0.2\n",
    "    time_mask: float = 0.3\n",
    "\n",
    "class Augmenter:\n",
    "    \"\"\"\n",
    "    Composable time-series augs tailored to wrist accelerometer windows.\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg: AugmentConfig | None = None):\n",
    "        # if None, fall back to defaults\n",
    "        self.cfg = cfg or AugmentConfig()\n",
    "\n",
    "    @classmethod\n",
    "    def available_ops(cls) -> list[str]:\n",
    "        \"\"\"Ops = config fields that have a same-named augmentation method.\"\"\"\n",
    "        names = [f.name for f in fields(AugmentConfig)]  # preserves declaration order\n",
    "        return [n for n in names if hasattr(cls, n) and callable(getattr(cls, n))]\n",
    "\n",
    "    def probs(self) -> dict[str, float]:\n",
    "        \"\"\"Current op -> probability mapping from the config.\"\"\"\n",
    "        return {n: getattr(self.cfg, n) for n in self.available_ops()}\n",
    "\n",
    "    # ---- primitive ops: (C, L) -> (C, L) ----\n",
    "    @staticmethod\n",
    "    def jitter(x: torch.Tensor, sigma: float = 0.01) -> torch.Tensor:\n",
    "        # add small Gaussian noise\n",
    "        return x + torch.randn_like(x) * sigma\n",
    "\n",
    "    @staticmethod\n",
    "    def scaling(x: torch.Tensor, sigma: float = 0.1) -> torch.Tensor:\n",
    "        # per-sample scalar scale ~ N(1, sigma^2)\n",
    "        s = torch.randn((), device=x.device) * sigma + 1.0  # shape ()\n",
    "        return x * s\n",
    "\n",
    "    @staticmethod\n",
    "    def time_flip(x: torch.Tensor) -> torch.Tensor:\n",
    "        # reverse along time axis\n",
    "        return torch.flip(x, dims=[-1])\n",
    "\n",
    "    @staticmethod\n",
    "    def axis_swap(x: torch.Tensor) -> torch.Tensor:\n",
    "        # swap y and z (requires >=3 channels); no-op otherwise\n",
    "        if x.size(0) >= 3:\n",
    "            return x[[0, 2, 1], :]\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def time_mask(x: torch.Tensor, max_frac: float = 0.1) -> torch.Tensor:\n",
    "        # zero a contiguous span of the series\n",
    "        L = x.size(-1)\n",
    "        w = max(1, int(L * max_frac))\n",
    "        start = random.randint(0, L - w)\n",
    "        y = x.clone()\n",
    "        y[:, start:start + w] = 0\n",
    "        return y\n",
    "\n",
    "    # --- pipelines ---\n",
    "    def view(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Stochastic augmentation pipeline.\n",
    "        \"\"\"\n",
    "        if random.random() < self.cfg.jitter:\n",
    "            x = self.jitter(x)\n",
    "        if random.random() < self.cfg.scaling:\n",
    "            x = self.scaling(x)\n",
    "        if random.random() < self.cfg.axis_swap:\n",
    "            x = self.axis_swap(x)\n",
    "        if random.random() < self.cfg.time_mask:\n",
    "            x = self.time_mask(x)\n",
    "        if random.random() < self.cfg.time_flip:\n",
    "            x = self.time_flip(x)\n",
    "        return x\n",
    "\n",
    "    def two_views(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        return self.view(x), self.view(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c218c4",
   "metadata": {},
   "source": [
    "### Visualising augmentations\n",
    "Below we sample an accelerometer segment. To ensure the segment is interesting, we pick one with a high standard deviation. Your job is to go through each of the augmentations, apply them, and document how each augmentation changes the accelerometer data.\n",
    "\n",
    "Then, re-examine what happens if you augment a segment with a much lower standard deviation. Is it still easy to detect the difference between the augmented and unaugmented signal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f1699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SD of each segment and pick the 90th percentile example\n",
    "sds = np.std(x_tr, axis=(1,2)) \n",
    "p90 = np.percentile(sds, 90)\n",
    "argp90 = np.argmin(np.abs(sds - p90))\n",
    "x_org = x_tr[argp90]\n",
    "\n",
    "# Visualise the original segment\n",
    "fig, ax = ssl.visualize_segment(x_org, title=\"Original\")\n",
    "\n",
    "# Apply augmentations to it to figure out what each is doing\n",
    "aug = Augmenter()\n",
    "\n",
    "x_org =  torch.from_numpy(x_org) # Convert segment to tensor\n",
    "\n",
    "# Jitter \n",
    "x_jitter = aug.jitter(x_org, sigma=0.2)\n",
    "fig, ax = ssl.visualize_segment(x_jitter.numpy(), title=\"Jittered\")\n",
    "\n",
    "# Scaling \n",
    "x_scale = aug.scaling(x_org, sigma=0.5)\n",
    "fig, ax = ssl.visualize_segment(x_scale.numpy(), title=\"Scaled\")\n",
    "\n",
    "# Time flip \n",
    "x_flip = aug.time_flip(x_org)\n",
    "fig, ax = ssl.visualize_segment(x_flip.numpy(), title=\"Time Flipped\")\n",
    "\n",
    "# Axis Swap \n",
    "x_swap = aug.axis_swap(x_org)\n",
    "fig, ax = ssl.visualize_segment(x_swap.numpy(), title=\"Axis Swapped\")\n",
    "\n",
    "# Time Mask \n",
    "x_mask = aug.time_mask(x_org, max_frac=0.1)\n",
    "fig, ax = ssl.visualize_segment(x_mask.numpy(), title=\"Time Masked\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9214ca7d",
   "metadata": {},
   "source": [
    "# Part 2: Experiment 1 - Augmentation Recognition Pre-training & Fine-tuning\n",
    "So far, we have split data into training, validation and test splits, and we have explored different ways of augmenting segments of accelerometer data. \n",
    "Let's now use these augmentations to implement a SSL method: Augmentation recognition pretraining. In this method, we train a model to recognise when different augmentations have been applied to a data-set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9293409e",
   "metadata": {},
   "source": [
    "## 1.1: Pre-training Setup\n",
    "Preparing data-sets of augmented accelerometers segments.\n",
    "Goals: \n",
    "- Data-set of augmented segments (X), where the applied augmentations are documented (y),\n",
    "- Introduce configs and keeping track of all the hyperparameters which impact model performance,\n",
    "- Create a data-loader which samples more-informative samples,\n",
    "- Check that a batch of data looks reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56797853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data-set!\n",
    " \n",
    "# Implement the AugRec __getitem__ method.\n",
    "class AugRecDataset(ssl.BaseWearableDataset):\n",
    "    def __init__(self, *args, multi_label: bool = True, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.multi_label = multi_label\n",
    "        self.ops = self.aug.available_ops()          # dynamic, ordered\n",
    "        self._op_probs = self.aug.probs()            # dict for quick lookup\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self._get_x(idx)                         # (C, L)\n",
    "        labels = torch.zeros(len(self.ops), dtype=torch.float32)\n",
    "\n",
    "        for k, op in enumerate(self.ops):\n",
    "            p = self._op_probs[op]\n",
    "            if random.random() < p:\n",
    "                labels[k] = 1.0\n",
    "                x = getattr(self.aug, op)(x)         # call op by name\n",
    "\n",
    "        if not self.multi_label:\n",
    "            labels = labels.max().unsqueeze(0)       # binary: any-aug\n",
    "\n",
    "        return x, labels\n",
    "    \n",
    "# Define the train data-set, visualise one of the (X,y) pairs\n",
    "aug_cfg = AugmentConfig() # Make any changes to the augmentation config here\n",
    "aug = Augmenter(cfg=aug_cfg) \n",
    "train_dataset = AugRecDataset(\n",
    "    X=x_tr,\n",
    "    y=y_tr,\n",
    "    augmenter=aug,\n",
    ")\n",
    "\n",
    "# Let's visualise one of the data-points before augmentation, and after augmentations\n",
    "x_org = x_tr[argp90]\n",
    "fig, ax = ssl.visualize_segment(x_org, title=\"Original\")\n",
    "\n",
    "x_train, y_train = train_dataset[argp90]\n",
    "appl_augs = \", \".join([aug.available_ops()[k] for k, b in enumerate(y_train) if b > 0])\n",
    "fig, ax = ssl.visualize_segment(x_train, title=appl_augs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf40f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a train config to keep track of training hyperparameters\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    seed: int = 42\n",
    "    batch_size: int = 8 # The number of training examples we use to estimate the loss from\n",
    "    num_workers: int = 2 # The number of workers involved in preparing training examples in parallel\n",
    "    max_epochs: int = 3\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 1e-4\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train_cfg = TrainConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f13ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data-loaders that efficiently sample and batch the data for model training\n",
    "# weights from std (as you had)\n",
    "def make_weights(values: np.ndarray, alpha: float = 1.0) -> torch.Tensor:\n",
    "    v = values - values.min()\n",
    "    if v.max() > 0: v = v / v.max()\n",
    "    v = (v + 1e-6) ** alpha\n",
    "    return torch.from_numpy(v.astype(np.float32))\n",
    "\n",
    "# assume x_tr, x_val are (N,C,L) and exist already\n",
    "sds = np.std(x_tr, axis=(1, 2))\n",
    "sds = np.nan_to_num(sds, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "weights = make_weights(sds, alpha=2.0)\n",
    "\n",
    "sampler = WeightedRandomSampler(weights=weights, num_samples=len(weights), replacement=True)\n",
    "\n",
    "aug_train = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=train_cfg.batch_size,\n",
    "    sampler=sampler, # comment out this line to see the impact of sampling!\n",
    "    shuffle=False,\n",
    "    num_workers=train_cfg.num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "aug_val = DataLoader(\n",
    "    dataset=AugRecDataset(X=x_val, augmenter=Augmenter(cfg=aug_cfg)),\n",
    "    batch_size=train_cfg.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=train_cfg.num_workers,\n",
    ")\n",
    "\n",
    "# Visualise samples in one batch - here you can compare the difference including the sampler makes!\n",
    "check_batch = next(iter(aug_train))\n",
    "\n",
    "for x_train, y_train in list(zip(*check_batch))[:4]:\n",
    "    appl_augs = \", \".join([aug.available_ops()[k] for k, b in enumerate(y_train) if b > 0])\n",
    "    fig, ax = ssl.visualize_segment(x_train, title=appl_augs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5cfa91",
   "metadata": {},
   "source": [
    "## 1.2 Initialise and Pre-train the Augmentation Recognition Model\n",
    "- Model is based on OxWearables/ssl-wearables model, and we wrap the backbone of the model in task specific heads\n",
    "- Again, use config to keep track of hyperparameters\n",
    "\n",
    "Goals:\n",
    "- Check that the model can do a forward pass of one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1e547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model! \n",
    "model_cfg = ssl.SSLConfig(\n",
    "    hub=ssl.HubConfig(pretrained=True),\n",
    "    model=ssl.ModelConfig(\n",
    "        in_channels=3,\n",
    "        input_len=900,\n",
    "        proj_dim=128,\n",
    "        num_classes=len(le.classes_),\n",
    "        k_labels=len(train_dataset.ops),\n",
    "        freeze_backbone=False),\n",
    ")\n",
    "\n",
    "model = ssl.SSLNet(model_cfg)\n",
    "\n",
    "x_batch, y_batch = check_batch\n",
    "with torch.inference_mode():\n",
    "    aug_pred = model(x_batch, head=\"aug\")   # logits (1, k_labels)\n",
    "\n",
    "print(\"Input shape:\", tuple(x_batch.shape))\n",
    "print(\"Model aug_pred shape:\", tuple(aug_pred.shape))\n",
    "print(\"Ground truth label shape:\", tuple(y_batch.shape))\n",
    "\n",
    "print(\"\\nRaw aug_pred logits:\\n\", aug_pred[0])\n",
    "pred_bin = (aug_pred > 0).int()  # naive threshold at 0\n",
    "print(\"\\nNaive binarized predictions:\\n\", pred_bin[0])\n",
    "print(\"\\nGround truth labels:\\n\", y_batch[0])\n",
    "# Untrained models predictions shouldn't match "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d3be4f",
   "metadata": {},
   "source": [
    "### Check that we can overfit a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbbdea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model can overfit to one batch\n",
    "def overfit_one_batch_augrec(model, dl, steps=100, lr=1e-2, device=\"cpu\"):\n",
    "    model.train().to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    b = next(iter(dl))\n",
    "    x, y = b[0].to(device), b[1].to(device)\n",
    "\n",
    "    print(f\"[Overfit-check] batch shape: x={tuple(x.shape)}, y={tuple(y.shape)}\")\n",
    "    losses = []\n",
    "    for t in range(steps):\n",
    "        # =========== This defines the logic for augmentation \n",
    "        logits = model(x, head=\"aug\")\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, y)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        losses.append(loss.item())\n",
    "        if (t+1) % max(1, steps//5) == 0:\n",
    "            print(f\" step {t+1:03d} | loss {losses[-1]:.4f}\")\n",
    "    print(f\" start loss={losses[0]:.4f}  end loss={losses[-1]:.4f}\")\n",
    "    return losses\n",
    "\n",
    "losses = overfit_one_batch_augrec(model, aug_train, lr=train_cfg.lr, device=train_cfg.device)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,2))\n",
    "ax.plot(losses)\n",
    "ax.set_xlabel(\"Step\")\n",
    "ax.set_ylabel(\"CE \")\n",
    "ax.set_title(\"Loss trajectory overfitting a single batch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ca8994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do model pretraining\n",
    "def augrec_pretraining(\n",
    "    model: nn.Module,\n",
    "    train_dl: DataLoader,\n",
    "    val_dl: DataLoader,\n",
    "    device: str = \"cpu\",\n",
    "    lr: float = 1e-3,\n",
    "    weight_decay: float = 1e-4,\n",
    "    max_epochs: int = 20,\n",
    ") -> Dict[str, List[float]]:\n",
    "    \"\"\"\n",
    "    Simple augmentation-recognition training loop.\n",
    "\n",
    "    Args:\n",
    "        model: nn.Module with an augmentation head (called with head=\"aug\")\n",
    "        train_dl: DataLoader yielding (x, y) batches for training\n",
    "        val_dl: DataLoader yielding (x, y) batches for validation\n",
    "        device: device string (\"cpu\" or \"cuda\")\n",
    "        lr: learning rate\n",
    "        weight_decay: weight decay for Adam optimizer\n",
    "        max_epochs: number of epochs to train\n",
    "\n",
    "    Returns:\n",
    "        history: dictionary with lists of per-epoch train and val loss\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    history: Dict[str, List[float]] = {\"train_loss\": [], \"val_loss\": []}\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        # ---- training ----\n",
    "        model.train()\n",
    "        train_loss_sum, n = 0.0, 0\n",
    "        for x, y in tqdm(train_dl):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x, head=\"aug\")\n",
    "            loss = F.binary_cross_entropy_with_logits(logits, y)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            train_loss_sum += loss.item() * x.size(0)\n",
    "            n += x.size(0)\n",
    "        train_loss = train_loss_sum / max(1, n)\n",
    "\n",
    "        # ---- validation ----\n",
    "        model.eval()\n",
    "        val_loss_sum, n = 0.0, 0\n",
    "        with torch.inference_mode():\n",
    "            for x, y in tqdm(val_dl):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                logits = model(x, head=\"aug\")\n",
    "                loss = F.binary_cross_entropy_with_logits(logits, y)\n",
    "                val_loss_sum += loss.item() * x.size(0)\n",
    "                n += x.size(0)\n",
    "        val_loss = val_loss_sum / max(1, n)\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "\n",
    "        print(f\"[AugRec] epoch {epoch:03d}  train {train_loss:.4f}  val {val_loss:.4f}\")\n",
    "\n",
    "    return history\n",
    "\n",
    "# Do the actual training!\n",
    "hist_ar = augrec_pretraining(model, aug_train, aug_val, \n",
    "                     device=train_cfg.device,\n",
    "                     lr=train_cfg.lr, weight_decay=train_cfg.weight_decay,\n",
    "                     max_epochs=train_cfg.max_epochs)\n",
    "\n",
    "\n",
    "# Plot train, val loss trajectories\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(hist_ar[\"train_loss\"], label=\"Train\")\n",
    "ax.plot(hist_ar[\"val_loss\"], label=\"Val\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"CE loss\")\n",
    "ax.set_title(\"AugRec training trajectory\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6ffadf",
   "metadata": {},
   "source": [
    "## 1.3 Fine-tune the AR Model\n",
    "We have trained a backbone model, now let's do **supervised** fine-tuning using the model to see it's performance for activity recognition\n",
    "\n",
    "Goals:\n",
    "- Learn how to freeze different components of the model\n",
    "- Implement supervised training loop\n",
    "- Get evaluation metrics on the validation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2d35e4",
   "metadata": {},
   "source": [
    "### Freezing parts of a model\n",
    "In PyTorch, every parameter (nn.Parameter) has a boolean flag `requires_grad`. During the backward pass, autograd only computes gradients for parameters with requires_grad=True. Optimizers (e.g. Adam) only update parameters that have a non-None .grad. So if you set p.requires_grad = False, then:\n",
    "- No gradient is computed for that parameter.\n",
    "- Its .grad stays None.\n",
    "- The optimizer skips updating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2719636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model component freezing\n",
    "for p in model.backbone.parameters(): p.requires_grad = False\n",
    "for p in model.proj.parameters():     p.requires_grad = False\n",
    "for p in model.aug_head.parameters(): p.requires_grad = False\n",
    "for p in model.cls_head.parameters(): p.requires_grad = True # just unfreeze a classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba0aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_finetuning(\n",
    "    model: nn.Module,\n",
    "    train_dl: DataLoader,\n",
    "    val_dl: DataLoader,\n",
    "    device: str = \"cpu\",\n",
    "    lr: float = 5e-4,\n",
    "    weight_decay: float = 1e-4,\n",
    "    max_epochs: int = 10,\n",
    ") -> Dict[str, List[float]]:\n",
    "    \"\"\"\n",
    "    Supervised training loop (no freezing here). Tracks loss only.\n",
    "    Expects model(x, head='cls') -> logits [B, C]; y is Long [B].\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    history: Dict[str, List[float]] = {\"train_loss\": [], \"val_loss\": []}\n",
    "    train_loss_sum, n = 0.0, 0\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        # --- train ---\n",
    "        model.train()\n",
    "        train_loss_sum, n = 0.0, 0\n",
    "        for x, y in tqdm(train_dl):\n",
    "            x, y = x.to(device), y.to(device).long()\n",
    "            logits = model(x, head=\"cls\")\n",
    "            loss = ce(logits, y)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            train_loss_sum += loss.item() * x.size(0)\n",
    "            n += x.size(0)\n",
    "        train_loss = train_loss_sum / max(1, n)\n",
    "\n",
    "        # --- validate ---\n",
    "        model.eval()\n",
    "        val_loss_sum, n = 0.0, 0\n",
    "        with torch.inference_mode():\n",
    "            for x, y in tqdm(val_dl):\n",
    "                x, y = x.to(device), y.to(device).long()\n",
    "                logits = model(x, head=\"cls\")\n",
    "                loss = ce(logits, y)\n",
    "                val_loss_sum += loss.item() * x.size(0)\n",
    "                n += x.size(0)\n",
    "        val_loss = val_loss_sum / max(1, n)\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        print(f\"[Supervised] epoch {epoch:03d}  train {train_loss:.4f}  val {val_loss:.4f}\")\n",
    "\n",
    "    return history\n",
    "\n",
    "# Do the actual training!\n",
    "sup_train = DataLoader(\n",
    "    ssl.BaseWearableDataset(X=x_tr, y=y_tr, augmenter=None), \n",
    "    batch_size=train_cfg.batch_size, shuffle=True, num_workers=train_cfg.num_workers\n",
    ")\n",
    "sup_val = DataLoader(\n",
    "    ssl.BaseWearableDataset(X=x_val, y=y_val, augmenter=None),\n",
    "    batch_size=train_cfg.batch_size, shuffle=False, num_workers=train_cfg.num_workers\n",
    ")\n",
    "sup_test = DataLoader(\n",
    "    ssl.BaseWearableDataset(X=x_te, y=y_te, augmenter=None),\n",
    "    batch_size=train_cfg.batch_size, shuffle=False, num_workers=train_cfg.num_workers\n",
    ")\n",
    "\n",
    "hist_sf = supervised_finetuning(model, sup_train, sup_val, \n",
    "                     device=train_cfg.device,\n",
    "                     lr=train_cfg.lr, weight_decay=train_cfg.weight_decay,\n",
    "                     max_epochs=train_cfg.max_epochs)\n",
    "\n",
    "\n",
    "# Plot train, val loss trajectories\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(hist_sf[\"train_loss\"], label=\"Train\")\n",
    "ax.plot(hist_sf[\"val_loss\"], label=\"Val\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"CE loss\")\n",
    "ax.set_title(\"Supervised finetuning training trajectory\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019d95a1",
   "metadata": {},
   "source": [
    "## 1.4: Final Test Set Evaluation for the Augmentation Recognition Model\n",
    "Look at peformance metrics of the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f16f7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    model: nn.Module,\n",
    "    dl: DataLoader,\n",
    "    device: str = \"cpu\",\n",
    "    label_names: Optional[List[str]] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Runs inference and returns accuracy, macro/weighted F1, and per-class PRF.\n",
    "    \"\"\"\n",
    "    model.eval().to(device)\n",
    "    all_true, all_pred = [], []\n",
    "    ce = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "    loss_sum, n = 0.0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for x, y in dl:\n",
    "            x, y = x.to(device), y.to(device).long()\n",
    "            logits = model(x, head=\"cls\")\n",
    "            loss_sum += ce(logits, y).item()\n",
    "            n += x.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            all_true.append(y.cpu().numpy())\n",
    "            all_pred.append(preds.cpu().numpy())\n",
    "\n",
    "    avg_loss = loss_sum / max(1, n)\n",
    "    y_true = np.concatenate(all_true) if all_true else np.array([], dtype=int)\n",
    "    y_pred = np.concatenate(all_pred) if all_pred else np.array([], dtype=int)\n",
    "\n",
    "    if y_true.size == 0:\n",
    "        return {}\n",
    "\n",
    "    # infer class count\n",
    "    num_classes = int(max(y_true.max(), y_pred.max()) + 1)\n",
    "    print(num_classes)\n",
    "\n",
    "    prec, rec, f1, support = precision_recall_fscore_support(\n",
    "        y_true, y_pred, labels=list(range(num_classes)), zero_division=0\n",
    "    )\n",
    "    metrics = {\n",
    "        \"loss\": avg_loss,\n",
    "        \"accuracy\": float(accuracy_score(y_true, y_pred)),\n",
    "        \"f1_macro\": float(f1_score(y_true, y_pred, average=\"macro\", zero_division=0)),\n",
    "        \"f1_weighted\": float(f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)),\n",
    "        \"per_class\": [\n",
    "            {\n",
    "                \"class\": (label_names[k] if label_names is not None and k < len(label_names) else str(k)),\n",
    "                \"precision\": float(prec[k]),\n",
    "                \"recall\": float(rec[k]),\n",
    "                \"f1\": float(f1[k]),\n",
    "                \"support\": int(support[k]),\n",
    "            }\n",
    "            for k in range(num_classes)\n",
    "        ],\n",
    "    }\n",
    "    # Print summary of performance\n",
    "    print(f\"[Eval] loss {avg_loss:.4f}  F1(macro) {metrics['f1_macro']:.3f}  F1(weighted) {metrics['f1_weighted']:.3f}\")\n",
    "    header = f\"{'Class':15s} {'Prec':>8s} {'Rec':>8s} {'F1':>8s} {'Support':>8s}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "    for row in metrics[\"per_class\"]:\n",
    "        print(f\"{row['class']:15s} \"\n",
    "            f\"{row['precision']:8.3f} \"\n",
    "            f\"{row['recall']:8.3f} \"\n",
    "            f\"{row['f1']:8.3f} \"\n",
    "            f\"{row['support']:8d}\") \n",
    "    return metrics\n",
    "\n",
    "ar_metrics = evaluate(model, sup_test, device=train_cfg.device, label_names=le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4708f5",
   "metadata": {},
   "source": [
    "# Part 3: Experiment 2 - Contrastive Learning \n",
    "This part of the noteboook notebook implements the **joint-embedding (contrastive)** paradigm of self-supervised learning. The goal is to teach the model to learn that two differently augmented views of the same signal are *similar*, while views from different signals are *dissimilar*.\n",
    "\n",
    "The core components are:\n",
    "\n",
    "1. **A** ```ContrastiveDataset```: For each sample, it returns two independently augmented 'views' (```v1```, ```v2```).\n",
    "\n",
    "2. **A Projection Head**: The model projects the backbone's features into a smaller, normalised space where similarity is measured. \n",
    "\n",
    "3. **An NT-Xent Loss Function**: This contrastive loss function encourages the projected views from the same source sample to be close together, while pushing views from different samples far apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ddb209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to reuse the datasets and augmenters from before.\n",
    "# The Augmenter class provides the `two_views` method which is perfect for contrastive learning.\n",
    "aug_cfg = ssl.AugmentConfig()\n",
    "aug = ssl.Augmenter(cfg=aug_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887672d5",
   "metadata": {},
   "source": [
    "## 2.1: Pre-training Setup\n",
    "Here, we set up the components needed for the contrastive task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9941d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the ContrastiveDataset from ssl_utils.py.\n",
    "# Its __getitem__ method returns two different augmented views of the same sample.\n",
    "# Unlike AugRecDataset, it doesn't provide labels (Y) as they are not needed for contrastive learning.\n",
    "train_dataset = ssl.ContrastiveDataset(\n",
    "    X=x_tr,\n",
    "    augmenter=aug\n",
    ")\n",
    "\n",
    "val_dataset = ssl.ContrastiveDataset(\n",
    "    X=x_val, \n",
    "    augmenter=aug\n",
    ")\n",
    "\n",
    "# Let's take the train set and visualise the two views for one segment\n",
    "sds = np.std(x_tr, axis=(1,2))\n",
    "p90 = np.percentile(sds, 90)\n",
    "argp90 = np.argmin(np.abs(sds-p90))\n",
    "\n",
    "v1, v2 = train_dataset[argp90]\n",
    "ssl.visualize_segment(x_tr[argp90], title=\"Original Signal\")\n",
    "ssl.visualize_segment(v1, title=\"View 1\")\n",
    "ssl.visualize_segment(v2, title=\"View 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3deed4",
   "metadata": {},
   "source": [
    "### Define a train config\n",
    "We add a **temperature (Ï„)** parameter for the NT-Xent loss. It's a small positive number that scales the similarity scores before they are fed into the loss function. A lower temperature makes the differences between similarities more pronounced, forcing the model to work harder to distinguish between easy and hard negative examples.\n",
    "\n",
    "It's a key hyperparameter in contrastive learning that helps the model with learning learning better representations effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df428d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainConfig:\n",
    "    seed: int = 42\n",
    "    batch_size: int = 16 # Contrastive learning benefits from larger batch sizes\n",
    "    num_workers: int = 2\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 1e-4\n",
    "    max_epochs: int = 5 # Let's train for a bit longer\n",
    "    patience: int = 3\n",
    "    temperature: float = 0.1 \n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train_cfg = TrainConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae49138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data-loaders with the weighted sampler, as before\n",
    "def make_weights(values: np.ndarray, alpha: float = 1.0) -> torch.Tensor:\n",
    "    v = values - values.min()\n",
    "    if v.max() > 0: v = v / v.max()\n",
    "    v = (v + 1e-6) ** alpha\n",
    "    return torch.from_numpy(v.astype(np.float32))\n",
    "\n",
    "sds = np.std(x_tr, axis=(1, 2))\n",
    "sds = np.nan_to_num(sds, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "weights = make_weights(sds, alpha=2.0)\n",
    "sampler = WeightedRandomSampler(weights=weights, num_samples=len(weights), replacement=True)\n",
    "\n",
    "contrastive_train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=train_cfg.batch_size,\n",
    "    sampler=sampler,\n",
    "    shuffle=False,\n",
    "    num_workers=train_cfg.num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "contrastive_val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=train_cfg.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=train_cfg.num_workers \n",
    "    # No sampler because we want to validate on a representative set, rather than picking biased, high-intensity samples like in training\n",
    "    # pin_memory not required as validation less compute-intensive\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3596e304",
   "metadata": {},
   "source": [
    "## 2.2: Initialise and Pre-train the Contrastive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a482d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model. The SSLNet from ssl_utils is already set up with a projection head.\n",
    "model_cfg_contrastive = ssl.SSLConfig(\n",
    "    model=ssl.ModelConfig(\n",
    "        in_channels=3, # The X,Y,Z accelerometry channels\n",
    "        proj_dim=128, # Dimension of the space for contrastive loss (projection head output)\n",
    "        num_classes=4, # For the downstream task (Non-wear, Sedentary, LPA, MVPA)\n",
    "        freeze_backbone=False # We want to continue training the whole model (not just fine-tuning the head)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Re-initialising model for contrastive learning...\n",
    "model_contrastive = ssl.SSLNet(model_cfg_contrastive)\n",
    "\n",
    "# Check the output of the projection head \n",
    "v1_batch, v2_batch = next(iter(contrastive_train_loader))\n",
    "with torch.inference_mode():\n",
    "    z1 = model_contrastive(v1_batch, head=\"proj\")\n",
    "    z2 = model_contrastive(v2_batch, head=\"proj\")\n",
    "\n",
    "print(\"Input view shape:\", tuple(v1_batch.shape))\n",
    "print(\"Projected embedding shape (z1): \", tuple(z1.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a6b127",
   "metadata": {},
   "source": [
    "### Sanity Check: Overfitting a Single Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1a01a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new sanity check function for the contrastive task.\n",
    "def overfit_one_batch_contrastive(model, dl, steps=100, lr=1e-3, temp=0.1, device=\"cpu\"):\n",
    "    model.train().to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    v1, v2 = next(iter(dl))\n",
    "    v1, v2 = v1.to(device), v2.to(device)\n",
    "\n",
    "    print(f\"[Overfit-check] batch shape: v1={tuple(v1.shape)}, v2={tuple(v2.shape)}\")\n",
    "    losses = []\n",
    "\n",
    "    for t in range(steps):\n",
    "        z1 = model(v1, head=\"proj\")\n",
    "        z2 = model(v2, head=\"proj\")\n",
    "        loss = ssl.nt_xent_loss(z1, z2, temperature=temp) \n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        losses.append(loss.item())\n",
    "        if (t+1) % max(1, steps//5) == 0:\n",
    "            print(f\" step {t+1:03d} | loss {losses[-1]:.4f}\")\n",
    "    print(f\" start loss={losses[0]:.4f}  end loss={losses[-1]:.4f}\")\n",
    "    return losses\n",
    "\n",
    "_ = overfit_one_batch_contrastive(model_contrastive, contrastive_train_loader, lr=train_cfg.lr, temp=train_cfg.temperature, device=train_cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2bdc5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fd62bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do model pretraining using the contrastive task.\n",
    "# The Trainer in ssl_utils.py already has a 'fit_contrastive' method.\n",
    "trainer_contrastive = ssl.Trainer(train_cfg)\n",
    "hist_contrastive = trainer_contrastive.fit_contrastive(model_contrastive, contrastive_train_loader, contrastive_val_loader)\n",
    "\n",
    "# Plot train and val loss trajectories\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(hist_contrastive[\"train_loss\"], label=\"Train\")\n",
    "ax.plot(hist_contrastive[\"val_loss\"], label=\"Val\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"NT-Xent Loss\")\n",
    "ax.set_title(\"Contrastive Pre-Training Trajectory\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7754f06",
   "metadata": {},
   "source": [
    "## 2.3: Fine-tune the Contrastive Model\n",
    "Now that the model's feature extractor has been pre-trained using the contrastive objective, we can assess its performance. Like with the Augmentation Recognition model, we will **freeze the pre-trained backbone** and train only a simple linear classifier on top of it using the labeled data. This tests the quality of the learned features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5037a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can reuse the `sup_train` and `sup_val` DataLoaders from the first experiment.\n",
    "\n",
    "# The Trainer's finetune method will handle freezing the backbone and training the classifier head.\n",
    "print(\"Fine-tuning the contrastive-pretrained model\")\n",
    "\n",
    "finetune_results_con = trainer_contrastive.finetune(\n",
    "    model=model_contrastive, \n",
    "    train_dl=sup_train, \n",
    "    val_dl=sup_val, \n",
    "    label_names=le.classes_\n",
    ")\n",
    "\n",
    "# Plot the fine-tuning loss trajectory\n",
    "hist_finetune_con = finetune_results_con # The finetune method returns the history\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(hist_finetune_con[\"train_loss\"], label=\"Train\")\n",
    "ax.plot(hist_finetune_con[\"val_loss\"], label=\"Val\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Cross Entropy Loss\")\n",
    "ax.set_title(\"Contrastive Model: Fine-tuning Trajectory\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f53404",
   "metadata": {},
   "source": [
    "## 2.4: Final Test Set Evaluation for the Contrastive Model\n",
    "After fine-tuning, we perform a final evaluation on the held-out test set to get an unbiased measure of the model's performance on the Human Activity Recognition task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4909c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the fine-tuned model \n",
    "print(\"Final Evaluation on Test Set\")\n",
    "\n",
    "test_metrics_con = trainer_contrastive.evaluate(\n",
    "    model=model_contrastive, \n",
    "    test_dl=sup_test, \n",
    "    label_names=le.classes_\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Oxford_Wearables_Activity_Recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
