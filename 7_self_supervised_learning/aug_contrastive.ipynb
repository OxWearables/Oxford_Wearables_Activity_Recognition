{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "556a4897",
   "metadata": {},
   "source": [
    "# SSL learning\n",
    "Learning useful representations through recognising augmentations and matching augmented views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f52d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import utils.ssl_utils as ssl\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass, fields\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaadbf71",
   "metadata": {},
   "source": [
    "## Loading data and exploring augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2cb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare capture24 data and split into train, val and test splits\n",
    "dm = ssl.Capture24DataManager(srv_root=\"/srv\", local_root=\"..\")\n",
    "ssl.set_seed(42)\n",
    "dm.prepare() # checks everything is downloaded\n",
    "(\n",
    "    x_tr, y_tr, pid_tr, # x_tr: accel segements, y_tr: labels, pid_tr: participant ID\n",
    "    x_val, y_val, pid_val, \n",
    "    x_te, y_te, pid_te,\n",
    "    le # label encoder - maps from integer labels to strings\n",
    ") = dm.train_val_test_split(prop=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b7210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AugmentConfig:\n",
    "    jitter: float = 0.5\n",
    "    scaling: float = 0.5\n",
    "    time_flip: float = 0.5\n",
    "    axis_swap: float = 0.2\n",
    "    time_mask: float = 0.3\n",
    "\n",
    "class Augmenter:\n",
    "    \"\"\"\n",
    "    Composable time-series augs tailored to wrist accelerometer windows.\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg: AugmentConfig | None = None):\n",
    "        # if None, fall back to defaults\n",
    "        self.cfg = cfg or AugmentConfig()\n",
    "\n",
    "    @classmethod\n",
    "    def available_ops(cls) -> list[str]:\n",
    "        \"\"\"Ops = config fields that have a same-named augmentation method.\"\"\"\n",
    "        names = [f.name for f in fields(AugmentConfig)]  # preserves declaration order\n",
    "        return [n for n in names if hasattr(cls, n) and callable(getattr(cls, n))]\n",
    "\n",
    "    def probs(self) -> dict[str, float]:\n",
    "        \"\"\"Current op -> probability mapping from the config.\"\"\"\n",
    "        return {n: getattr(self.cfg, n) for n in self.available_ops()}\n",
    "\n",
    "    # ---- primitive ops: (C, L) -> (C, L) ----\n",
    "    @staticmethod\n",
    "    def jitter(x: torch.Tensor, sigma: float = 0.01) -> torch.Tensor:\n",
    "        # add small Gaussian noise\n",
    "        return x + torch.randn_like(x) * sigma\n",
    "\n",
    "    @staticmethod\n",
    "    def scaling(x: torch.Tensor, sigma: float = 0.1) -> torch.Tensor:\n",
    "        # per-sample scalar scale ~ N(1, sigma^2)\n",
    "        s = torch.randn((), device=x.device) * sigma + 1.0  # shape ()\n",
    "        return x * s\n",
    "\n",
    "    @staticmethod\n",
    "    def time_flip(x: torch.Tensor) -> torch.Tensor:\n",
    "        # reverse along time axis\n",
    "        return torch.flip(x, dims=[-1])\n",
    "\n",
    "    @staticmethod\n",
    "    def axis_swap(x: torch.Tensor) -> torch.Tensor:\n",
    "        # swap y and z (requires >=3 channels); no-op otherwise\n",
    "        if x.size(0) >= 3:\n",
    "            return x[[0, 2, 1], :]\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def time_mask(x: torch.Tensor, max_frac: float = 0.1) -> torch.Tensor:\n",
    "        # zero a contiguous span of the series\n",
    "        L = x.size(-1)\n",
    "        w = max(1, int(L * max_frac))\n",
    "        start = random.randint(0, L - w)\n",
    "        y = x.clone()\n",
    "        y[:, start:start + w] = 0\n",
    "        return y\n",
    "\n",
    "    # --- pipelines ---\n",
    "    def view(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Stochastic augmentation pipeline.\n",
    "        \"\"\"\n",
    "        if random.random() < self.cfg.jitter:\n",
    "            x = self.jitter(x)\n",
    "        if random.random() < self.cfg.scaling:\n",
    "            x = self.scaling(x)\n",
    "        if random.random() < self.cfg.axis_swap:\n",
    "            x = self.axis_swap(x)\n",
    "        if random.random() < self.cfg.time_mask:\n",
    "            x = self.time_mask(x)\n",
    "        if random.random() < self.cfg.time_flip:\n",
    "            x = self.time_flip(x)\n",
    "        return x\n",
    "\n",
    "    def two_views(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        return self.view(x), self.view(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c218c4",
   "metadata": {},
   "source": [
    "### Visualising augmentations\n",
    "Below we sample an accelerometer segment. To ensure the segment is interesting, we pick one with a high standard deviation. Your job is to go through each of the augmentations, apply them, and document how each augmentation changes the accelerometer data.\n",
    "\n",
    "Then, re-examine what happens if you augment a segment with a much lower standard deviation. Is it still easy to detect the difference between the augmented and unaugmented signal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f1699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SD of each segment and pick the 90th percentile example\n",
    "sds = np.std(x_tr, axis=(1,2)) \n",
    "p90 = np.percentile(sds, 90)\n",
    "argp90 = np.argmin(np.abs(sds - p90))\n",
    "x_org = x_tr[argp90]\n",
    "\n",
    "# Visualise the original segment\n",
    "fig, ax = ssl.visualize_segment(x_org, title=\"Original\")\n",
    "\n",
    "# Apply augmentations to it to figure out what each is doing\n",
    "aug = Augmenter()\n",
    "\n",
    "x_org =  torch.from_numpy(x_org) # Convert segment to tensor\n",
    "\n",
    "# Jitter \n",
    "x_jitter = aug.jitter(x_org, sigma=0.2)\n",
    "fig, ax = ssl.visualize_segment(x_jitter.numpy(), title=\"Jittered\")\n",
    "\n",
    "# Scaling \n",
    "x_scale = aug.scaling(x_org, sigma=0.5)\n",
    "fig, ax = ssl.visualize_segment(x_scale.numpy(), title=\"Scaled\")\n",
    "\n",
    "# Time flip \n",
    "x_flip = aug.time_flip(x_org)\n",
    "fig, ax = ssl.visualize_segment(x_flip.numpy(), title=\"Time Flipped\")\n",
    "\n",
    "# Axis Swap \n",
    "x_swap = aug.axis_swap(x_org)\n",
    "fig, ax = ssl.visualize_segment(x_swap.numpy(), title=\"Axis Swapped\")\n",
    "\n",
    "# Time Mask \n",
    "x_mask = aug.time_mask(x_org, max_frac=0.1)\n",
    "fig, ax = ssl.visualize_segment(x_mask.numpy(), title=\"Time Masked\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9214ca7d",
   "metadata": {},
   "source": [
    "## Augmentation recognition pretraining\n",
    "So far, we have split data into training, validation and test splits, and we have explored different ways of augmenting segments of accelerometer data. \n",
    "Let's now use these augmentations to implement a SSL method: Augmentation recognition pretraining. In this method, we train a model to recognise when different augmentations have been applied to a data-set.\n",
    "\n",
    "- Implement pretraining\n",
    "- Train model and plot loss trajectory\n",
    "- Fine-tune pretrained model and assess preformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56797853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data-set!\n",
    " \n",
    "# Implement the AugRec __getitem__ method.\n",
    "class AugRecDataset(ssl.BaseWearableDataset):\n",
    "    def __init__(self, *args, multi_label: bool = True, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.multi_label = multi_label\n",
    "        self.ops = self.aug.available_ops()          # dynamic, ordered\n",
    "        self._op_probs = self.aug.probs()            # dict for quick lookup\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self._get_x(idx)                         # (C, L)\n",
    "        labels = torch.zeros(len(self.ops), dtype=torch.float32)\n",
    "\n",
    "        for k, op in enumerate(self.ops):\n",
    "            p = self._op_probs[op]\n",
    "            if random.random() < p:\n",
    "                labels[k] = 1.0\n",
    "                x = getattr(self.aug, op)(x)         # call op by name\n",
    "\n",
    "        if not self.multi_label:\n",
    "            labels = labels.max().unsqueeze(0)       # binary: any-aug\n",
    "\n",
    "        return x, labels\n",
    "    \n",
    "# Define the train data-set, visualise one of the (X,y) pairs\n",
    "aug_cfg = AugmentConfig() # Make any changes to the augmentation config here\n",
    "aug = Augmenter(cfg=aug_cfg) \n",
    "train_dataset = AugRecDataset(\n",
    "    X=x_tr,\n",
    "    y=y_tr,\n",
    "    augmenter=aug,\n",
    ")\n",
    "\n",
    "# Let's visualise one of the data-points before augmentation, and after augmentations\n",
    "x_org = x_tr[argp90]\n",
    "fig, ax = ssl.visualize_segment(x_org, title=\"Original\")\n",
    "\n",
    "x_train, y_train = train_dataset[argp90]\n",
    "appl_augs = \", \".join([aug.available_ops()[k] for k, b in enumerate(y_train) if b > 0])\n",
    "fig, ax = ssl.visualize_segment(x_train, title=appl_augs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf40f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a train config!\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    seed: int = 42\n",
    "    batch_size: int = 8\n",
    "    num_workers: int = 2\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 1e-4\n",
    "    max_epochs: int = 3\n",
    "    patience: int = 1\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train_cfg = TrainConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f13ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data-loaders that efficiently sample and batch the data for model training\n",
    "# weights from std (as you had)\n",
    "def make_weights(values: np.ndarray, alpha: float = 1.0) -> torch.Tensor:\n",
    "    v = values - values.min()\n",
    "    if v.max() > 0: v = v / v.max()\n",
    "    v = (v + 1e-6) ** alpha\n",
    "    return torch.from_numpy(v.astype(np.float32))\n",
    "\n",
    "# assume x_tr, x_val are (N,C,L) and exist already\n",
    "sds = np.std(x_tr, axis=(1, 2))\n",
    "sds = np.nan_to_num(sds, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "weights = make_weights(sds, alpha=2.0)\n",
    "\n",
    "sampler = WeightedRandomSampler(weights=weights, num_samples=len(weights), replacement=True)\n",
    "\n",
    "aug_train = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=train_cfg.batch_size,\n",
    "    sampler=sampler, # comment out this line to see the impact of sampling!\n",
    "    shuffle=False,\n",
    "    num_workers=train_cfg.num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "aug_val = DataLoader(\n",
    "    dataset=AugRecDataset(X=x_val, augmenter=Augmenter(cfg=aug_cfg)),\n",
    "    batch_size=train_cfg.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=train_cfg.num_workers,\n",
    ")\n",
    "\n",
    "# Visualise samples in one batch - here you can compare the difference including the sampler makes!\n",
    "for check_batch in aug_train:\n",
    "    break\n",
    "for x_train, y_train in zip(*check_batch):\n",
    "    appl_augs = \", \".join([aug.available_ops()[k] for k, b in enumerate(y_train) if b > 0])\n",
    "    fig, ax = ssl.visualize_segment(x_train, title=appl_augs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1e547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model! \n",
    "model_cfg = ssl.SSLConfig(\n",
    "    hub=ssl.HubConfig(pretrained=True),\n",
    "    model=ssl.ModelConfig(\n",
    "        in_channels=3,\n",
    "        input_len=900,\n",
    "        proj_dim=128,\n",
    "        num_classes=4,\n",
    "        k_labels=len(train_dataset.ops),\n",
    "        freeze_backbone=False),\n",
    ")\n",
    "\n",
    "model = ssl.SSLNet(model_cfg)\n",
    "\n",
    "x_batch, y_batch = check_batch\n",
    "with torch.inference_mode():\n",
    "    aug_pred = model(x_batch, head=\"aug\")   # logits (1, k_labels)\n",
    "\n",
    "print(\"Input shape:\", tuple(x_batch.shape))\n",
    "print(\"Model aug_pred shape:\", tuple(aug_pred.shape))\n",
    "print(\"Ground truth label shape:\", tuple(y_batch.shape))\n",
    "\n",
    "print(\"\\nRaw aug_pred logits:\\n\", aug_pred)\n",
    "pred_bin = (aug_pred > 0).int()  # naive threshold at 0\n",
    "print(\"\\nNaive binarized predictions:\\n\", pred_bin)\n",
    "print(\"\\nGround truth labels:\\n\", y_batch)\n",
    "# Untrained models predictions shouldn't match "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbbdea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model can overfit to one batch\n",
    "def overfit_one_batch_augrec(model, dl, steps=100, lr=1e-2, device=\"cpu\"):\n",
    "    model.train().to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    b = next(iter(dl))\n",
    "    x, y = b[0].to(device), b[1].to(device)\n",
    "\n",
    "    print(f\"[Overfit-check] batch shape: x={tuple(x.shape)}, y={tuple(y.shape)}\")\n",
    "    losses = []\n",
    "    for t in range(steps):\n",
    "        logits = model(x, head=\"aug\")\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, y)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        losses.append(loss.item())\n",
    "        if (t+1) % max(1, steps//5) == 0:\n",
    "            print(f\" step {t+1:03d} | loss {losses[-1]:.4f}\")\n",
    "    print(f\" start loss={losses[0]:.4f}  end loss={losses[-1]:.4f}\")\n",
    "    return losses\n",
    "\n",
    "_ = overfit_one_batch_augrec(model, aug_train, lr=train_cfg.lr, device=train_cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ce7215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, do model pretraining! ~ 7 minutes on GPU node\n",
    "trainer = ssl.Trainer(train_cfg)\n",
    "hist_ar = trainer.fit_augrec(model, aug_train, aug_val)\n",
    "\n",
    "# Plot train, val loss trajectories\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(hist_ar[\"train_loss\"], label=\"Train\")\n",
    "ax.plot(hist_ar[\"val_loss\"], label=\"Val\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"CE loss\")\n",
    "ax.set_title(\"AugRec training trajectory\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2b399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib; importlib.reload(ssl)\n",
    "\n",
    "trainer = ssl.Trainer(train_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a65297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build supervised datasets (labelled)\n",
    "sup_train = DataLoader(\n",
    "    ssl.BaseWearableDataset(X=x_tr, y=y_tr, augmenter=None), \n",
    "    batch_size=train_cfg.batch_size, shuffle=True, num_workers=train_cfg.num_workers\n",
    ")\n",
    "sup_val = DataLoader(\n",
    "    ssl.BaseWearableDataset(X=x_val, y=y_val, augmenter=None),\n",
    "    batch_size=train_cfg.batch_size, shuffle=False, num_workers=train_cfg.num_workers\n",
    ")\n",
    "\n",
    "# Finetune \n",
    "label_names = list(le.classes_) if le is not None else None\n",
    "finetune_out = trainer.finetune(model, sup_train, sup_val, label_names=label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e5f979",
   "metadata": {},
   "source": [
    "## Finetuning a pretrained SSL model\n",
    "- Explore different fine-tuning methods\n",
    "- Explore classification performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b251b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Oxford_Wearables_Activity_Recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
