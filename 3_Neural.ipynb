{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks in activity recognition\n",
    "\n",
    "Engineering effective features is one of the most time-consuming parts of\n",
    "machine learning.\n",
    "The appeal of neural networks is that feature enginnering is integrated into the\n",
    "training process &mdash; they automatically engineer features that are relevant\n",
    "for the learning task directly from the raw representation of the data\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import utils\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Grab a GPU if there is one\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using {} device: {}\".format(device, torch.cuda.current_device()))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using {}\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your extracted windows\n",
    "DATASET_PATH = 'processed_data/'\n",
    "print(f'Content of {DATASET_PATH}')\n",
    "print(os.listdir(DATASET_PATH))\n",
    "\n",
    "X = np.load(DATASET_PATH+'X.npy', mmap_mode='r')\n",
    "Y = np.load(DATASET_PATH+'Y.npy')\n",
    "T = np.load(DATASET_PATH+'T.npy')\n",
    "pid = np.load(DATASET_PATH+'pid.npy')\n",
    "\n",
    "# As before, let's map the text annotations to simplified labels\n",
    "ANNO_LABEL_DICT_PATH = 'capture24/annotation-label-dictionary.csv'\n",
    "anno_label_dict = pd.read_csv(ANNO_LABEL_DICT_PATH, index_col='annotation', dtype='string')\n",
    "Y = anno_label_dict.loc[Y, 'label:Willetts2018'].to_numpy()\n",
    "\n",
    "# Transform to numeric\n",
    "le = LabelEncoder().fit(Y)\n",
    "Y = le.transform(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold out participants P101-P151 for testing (51 participants)\n",
    "test_ids = [f'P{i}' for i in range(101,152)]\n",
    "mask_test = np.isin(pid, test_ids)\n",
    "mask_train = ~mask_test\n",
    "X_train, Y_train, T_train, pid_train = \\\n",
    "    X[mask_train], Y[mask_train], T[mask_train], pid[mask_train]\n",
    "X_test, Y_test, T_test, pid_test = \\\n",
    "    X[mask_test], Y[mask_test], T[mask_test], pid[mask_test]\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture design\n",
    "\n",
    "As a baseline, let's use a convolutional neural network (CNN) with a\n",
    "typical pyramid-like structure. The input to the network is a `(N,3,3000)`\n",
    "array, corresponding to `N` windows of raw tri-axial accelerometer measures.\n",
    "Note the transposed format `(3,3000)` instead of `(3000,3)`; this *channels\n",
    "first* format is the default in PyTorch.\n",
    "\n",
    "The output of the CNN is a `(N,num_labels)` array where each row contains\n",
    "predicted unnormalized class scores or *logits*; pass each row to a softmax\n",
    "if you want to convert it to probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNReLU(nn.Module):\n",
    "    ''' Convolution + batch normalization + ReLU is a common trio '''\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels,\n",
    "        kernel_size=3, stride=1, padding=1, bias=True\n",
    "    ):\n",
    "        super(ConvBNReLU, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels,\n",
    "                kernel_size, stride, padding, bias=bias),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    ''' Typical CNN design with pyramid-like structure '''\n",
    "    def __init__(self, output_size=5, in_channels=3, num_filters_init=8):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            ConvBNReLU(in_channels, num_filters_init,\n",
    "            8, 4, 2, bias=False),  # 1500 -> 750\n",
    "            ConvBNReLU(num_filters_init, num_filters_init*2,\n",
    "            6, 4, 2, bias=False),  # 750 -> 188\n",
    "            ConvBNReLU(num_filters_init*2, num_filters_init*4,\n",
    "            8, 4, 2, bias=False),  # 188 -> 47\n",
    "            ConvBNReLU(num_filters_init*4, num_filters_init*8,\n",
    "            3, 2, 1, bias=False),  # 47 -> 24\n",
    "            ConvBNReLU(num_filters_init*8, num_filters_init*16,\n",
    "            4, 2, 1, bias=False),  # 24 -> 12\n",
    "            ConvBNReLU(num_filters_init*16, num_filters_init*32,\n",
    "            4, 2, 1, bias=False),  # 12 -> 6\n",
    "            ConvBNReLU(num_filters_init*32, num_filters_init*64,\n",
    "            6, 1, 0, bias=False),  # 6 -> 1\n",
    "            nn.Conv1d(num_filters_init*64, output_size,\n",
    "            1, 1, 0, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x).view(x.shape[0],-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(X, y=None, batch_size=1, shuffle=False):\n",
    "    ''' Create a (batch) iterator over the dataset. Alternatively, you can use\n",
    "    PyTorch's Dataset and DataLoader classes -- See\n",
    "    https://pytorch.org/tutorials/beginner/data_loading_tutorial.html '''\n",
    "    if shuffle:\n",
    "        idxs = np.random.permutation(np.arange(len(X)))\n",
    "    else:\n",
    "        idxs = np.arange(len(X))\n",
    "    for i in range(0, len(idxs), batch_size):\n",
    "        idxs_batch = idxs[i:i+batch_size]\n",
    "        X_batch = X[idxs_batch].astype('f4')  # PyTorch defaults to float32\n",
    "        X_batch = np.transpose(X_batch, (0,2,1))  # channels first: (N,M,3) -> (N,3,M). PyTorch uses channel first format\n",
    "        X_batch = torch.from_numpy(X_batch)\n",
    "        if y is None:\n",
    "            yield X_batch\n",
    "        else:\n",
    "            y_batch = y[idxs_batch]\n",
    "            y_batch = torch.from_numpy(y_batch)\n",
    "            yield X_batch, y_batch\n",
    "\n",
    "\n",
    "def forward_by_batches(cnn, X):\n",
    "    ''' Forward pass model on a dataset.\n",
    "    Do this by batches so that we don't blow up the memory. '''\n",
    "    Y = []\n",
    "    cnn.eval()\n",
    "    with torch.no_grad():\n",
    "        for x in create_dataloader(X, batch_size=1024, shuffle=False):  # do not shuffle here!\n",
    "            x = x.to(device)\n",
    "            Y.append(cnn(x))\n",
    "    cnn.train()\n",
    "    Y = torch.cat(Y)\n",
    "    return Y\n",
    "\n",
    "\n",
    "def evaluate_model(cnn, X, Y):\n",
    "    Y_pred = forward_by_batches(cnn, X)  # scores\n",
    "    loss = F.cross_entropy(Y_pred, torch.from_numpy(Y).type(torch.int64).to(device)).item()\n",
    "\n",
    "    Y_pred = F.softmax(Y_pred, dim=1)  # convert to probabilities\n",
    "    Y_pred = torch.argmax(Y_pred, dim=1)  # convert to classes\n",
    "    Y_pred = Y_pred.cpu().numpy()  # cast to numpy array\n",
    "    kappa = metrics.cohen_kappa_score(Y, Y_pred)\n",
    "\n",
    "    return {'loss':loss, 'kappa':kappa, 'Y_pred':Y_pred}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Hyperparameters, model instantiation, loss function and optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters_init = 32  # initial num of filters -- see class definition\n",
    "in_channels = 3  # num of channels of the signal -- equal to 3 for our raw triaxial timeseries\n",
    "output_size = len(np.unique(Y))  # num of classes (sleep, sedentary, etc...)\n",
    "num_epoch = 1  # num of epochs (full loops though the training set)\n",
    "lr = 3e-4  # learning rate\n",
    "batch_size = 32  # size of the mini-batch\n",
    "\n",
    "cnn = CNN(\n",
    "    output_size=output_size,\n",
    "    in_channels=in_channels,\n",
    "    num_filters_init=num_filters_init\n",
    ").to(device)\n",
    "print(cnn)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa_history_test = []\n",
    "loss_history_test = []\n",
    "loss_history_train = []\n",
    "losses = []\n",
    "for i in range(num_epoch):\n",
    "    dataloader = create_dataloader(X_train, Y_train, batch_size, shuffle=True)\n",
    "    for x, target in tqdm(dataloader):\n",
    "        x, target = x.to(device), target.type(torch.int64).to(device)\n",
    "        cnn.zero_grad()\n",
    "        output = cnn(x)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Logging -- track train loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    #       Evaluate performance at the end of each epoch\n",
    "    # --------------------------------------------------------\n",
    "\n",
    "    # Logging -- average train loss in this epoch\n",
    "    loss_history_train.append(utils.ewm(losses))\n",
    "\n",
    "    # Logging -- evalutate performance on test set\n",
    "    results = evaluate_model(cnn, X_test, Y_test)\n",
    "    loss_history_test.append(results['loss'])\n",
    "    kappa_history_test.append(results['kappa'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss history\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(loss_history_train, color='C0', label='train loss')\n",
    "ax.plot(loss_history_test, color='C1', label='test loss')\n",
    "ax.set_ylabel('loss (CE)')\n",
    "ax.set_xlabel('epoch')\n",
    "ax = ax.twinx()\n",
    "ax.plot(kappa_history_test, color='C2', label='kappa')\n",
    "ax.set_ylabel('kappa')\n",
    "ax.grid(True)\n",
    "fig.legend()\n",
    "\n",
    "# Report\n",
    "Y_test_pred_lab = le.inverse_transform(results['Y_pred'])  # back to text labels\n",
    "Y_test_lab = le.inverse_transform(Y_test)  # back to text labels\n",
    "print('\\nClassifier performance')\n",
    "print('Out of sample:\\n', metrics.classification_report(Y_test_lab, Y_test_pred_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise**: Try improving the performance of the model. Here are some things to try:\n",
    "- Class balancing\n",
    "- Mode smoothing, HMM (Q: How to estimate the emission matrix?)\n",
    "- Architecture design, optimizer, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application to own data\n",
    "We are now going to see how well the model performs on the data your collected yesterday. In order to do this, you need the `.CWA` file from your accelerometer (which you can obtain by plugging your accelerometer into the computer, and finding it in Finder) and the `.csv` file that you obtained using the camera browser. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a folder called `my_data` in this repository for the `.csv` and `.CWA` files, and copy the files into this folder. By calling `ls my_data`, you should see these two files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls my_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next install [actipy](https://github.com/OxWearables/actipy). Actipy requires Java to be installed. If you are working on the virtual machines, this should already be set up. If you are working locally on your computer, you can do this using homebrew:\n",
    "```shell\n",
    "brew install java\n",
    "```\n",
    "Importantly, follow the suggestion from homebrew and and create a symbolic link to the homebrew installation. This command will look like:\n",
    "```shell\n",
    "sudo ln -sfn /opt/homebrew/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk\n",
    "``` \n",
    "Once java has been installed, you can import actipy using `pip`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import actipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you can process your accelerometer data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_my_data = \"my_data/CWA-DATA.CWA\" # Make sure you specify the right file name here\n",
    "\n",
    "my_data, info = actipy.read_device(path_to_my_data,\n",
    "                                   lowpass_hz=None,\n",
    "                                   calibrate_gravity=True,\n",
    "                                   detect_nonwear=True,\n",
    "                                   resample_hz=100)\n",
    "my_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_time_col(col):\n",
    "    col = col.str.slice(0,19) # 2022-11-28T12:00:00.000Z remove the three digits after the decimal relating to the images, \n",
    "    col = pd.to_datetime(col, format='%Y-%m-%dT%H:%M:%S') # parse to time\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_my_annots = \"my_data/annotation.csv\" # Make sure you specify the right file name here\n",
    "\n",
    "annots = pd.read_csv(path_to_my_annots)\n",
    "annots[\"startTime\"] = process_time_col(annots[\"startTime\"])\n",
    "annots[\"endTime\"] = process_time_col(annots[\"endTime\"])\n",
    "\n",
    "annots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data[\"annotation\"] = \"un_annotated\" # initially set data to un_annotated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now write some code to match up the annotations from the `.csv` file to the `.cwa` file. Below is some unoptimised code that just loops through the two files copy annotations if the timestamps match up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add annotations to data\n",
    "# first sort the two data-frames\n",
    "my_data = my_data.sort_values(\"time\")\n",
    "annots = annots.sort_values(\"startTime\")\n",
    "\n",
    "my_i = 0\n",
    "an_i = 0\n",
    "while(my_i<len(my_data) and an_i<len(annots)):\n",
    "    accel_time = my_data.index[my_i]\n",
    "    annot_start_time = annots[\"startTime\"][an_i]\n",
    "    annot_end_time = annots[\"endTime\"][an_i]\n",
    "    \n",
    "    if not (my_i % 1000):\n",
    "        print(f\"{my_i}/{len(my_data)} readings processed\", end=\"\\r\")\n",
    "\n",
    "    # check whether the current accel timestamp falls within the time frame of the current annotation\n",
    "    if accel_time >= annot_start_time and accel_time <= annot_end_time:\n",
    "        my_data.at[ my_data.index[my_i], \"annotation\" ] = annot_row[\"annotation\"]\n",
    "        my_i += 1 # go to next accel\n",
    "    \n",
    "    elif accel_time < annot_start_time:\n",
    "        my_i += 1 # go to next accel \n",
    "        \n",
    "    \n",
    "    elif accel_time > annot_end_time:\n",
    "        an_i += 1 # go to next label\n",
    "        \n",
    "    else: # shouldn't get here\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to process the annotated accelerometer data so that it is in the same shape as the data fed into the CNN. To do this, we need to break it up into windows first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_X, my_Y, my_T = utils.make_windows(my_data, winsec=30, sample_rate=100, dropna=False, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can put our data into the model, transform the outputs to probabilities, and look at which class has the highest probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = forward_by_batches(cnn, my_X)\n",
    "Y_pred = F.softmax(Y_pred, dim=1)  # convert to probabilities\n",
    "Y_pred = torch.argmax(Y_pred, dim=1)  # convert to classes\n",
    "Y_pred = Y_pred.cpu().numpy()  # cast to numpy array\n",
    "le.inverse_transform(Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do these match up with your annotations? Note: you may have to simplify your annoations using `anno_label_dict.loc[my_Y, 'label:Willetts2018'].to_numpy()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_Y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ba62a1b4a2d59cbe868c83bdd535aa95e1f6d51e6a8dbfe9705911f17ded0148"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
