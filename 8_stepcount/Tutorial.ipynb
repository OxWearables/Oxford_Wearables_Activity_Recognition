{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step counter tutorial\n",
    "\n",
    "This is a simple tutorial outlining the implementation of hybrid step count model produced by the OxWearables group.\n",
    "A more comprehensive detailing of this model can be found in Small et al. (2023)[[1]](https://www.medrxiv.org/content/10.1101/2023.02.20.23285750v1).\n",
    "\n",
    "The hybrid step count model consists of a peak detector, tuned to detect steps, and a walking detector, tuned to identify walking. \n",
    "The model is trained on data collected by Dr. Small as part of the OxWearables group, of 1 hour of annotated steps, with accelerometery recorded from the non dominant wrist at 100Hz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Import necessary packages\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict, LeaveOneGroupOut\n",
    "import shutil\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "import stepcount.features as features\n",
    "import stepcount.hmm_utils as hmm_utils\n",
    "import stepcount.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Download the OxWalk dataset\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "print(f\"Downloading OxWalk...\")\n",
    "url = \"https://ora.ox.ac.uk/objects/uuid:19d3cb34-e2b3-4177-91b6-1bad0e0163e7/files/dcj82k7829\"\n",
    "with urllib.request.urlopen(url) as f_src, open(\"OxWalk_Dec2022.zip\", \"wb\") as f_dst:\n",
    "    shutil.copyfileobj(f_src, f_dst)\n",
    "print(\"Unzipping...\")\n",
    "with zipfile.ZipFile(\"OxWalk_Dec2022.zip\", \"r\") as f:\n",
    "    f.extractall(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxwalk_dir = 'OxWalk_Dec2022/Wrist_100Hz/'\n",
    "SAMPLE_RATE = 100  # Hz\n",
    "WINDOW_SEC = 10  # seconds\n",
    "STEPTOL = 4  # count\n",
    "WINDOW_LEN = int(WINDOW_SEC * SAMPLE_RATE)  # ticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "#   Some utility functions\n",
    "# --------------------------\n",
    "\n",
    "def read_csv(filename):\n",
    "    \"\"\" Data loader \"\"\"\n",
    "\n",
    "    data = pd.read_csv(\n",
    "        filename, \n",
    "        parse_dates=['timestamp'], \n",
    "        index_col='timestamp',\n",
    "        dtype={\n",
    "            'x': 'f4', \n",
    "            'y': 'f4', \n",
    "            'z': 'f4', \n",
    "            'annotation': 'Int64',\n",
    "        }\n",
    "    )\n",
    "    return data\n",
    "\n",
    "\n",
    "def plotw(w, ax, lp=None, find_peaks=False, find_peaks_params=None):\n",
    "    \"\"\" Plot a window accel trace \"\"\"\n",
    "\n",
    "    v = np.linalg.norm(w[['x', 'y', 'z']].to_numpy(), axis=1)  # absolute accel magnitude\n",
    "    v = v - 1  # detrend: \"remove gravity\"\n",
    "\n",
    "    if lp:\n",
    "        # lowpass filter\n",
    "        v = features.butterfilt(v, lp, SAMPLE_RATE)\n",
    "\n",
    "    xanno = np.argwhere(w['annotation'].to_numpy()).ravel()\n",
    "    yanno = v[xanno]\n",
    "    ax.plot(v)\n",
    "    ax.scatter(xanno, yanno, marker='x', c='k', label='step')\n",
    "    title = f\"steps: {len(xanno)}\"\n",
    "\n",
    "    if find_peaks:\n",
    "        find_peaks_params = find_peaks_params or {}\n",
    "        peaks, _ = signal.find_peaks(v, **find_peaks_params)\n",
    "        ax.scatter(peaks, v[peaks], marker='o', fc='none', ec='r', label='find_peaks')\n",
    "        title = f\"{title} | find_peaks: {len(peaks)}\"\n",
    "\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    ax.set_title(title)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plotsome(data, **kwargs):\n",
    "    \"\"\" Plot some windows \"\"\"\n",
    "\n",
    "    NFIGS_WALK = 10  # walk windows to plot\n",
    "    NFIGS_NOTWALK = 5  # non-walk windows to plot\n",
    "    NFIGS = NFIGS_WALK + NFIGS_NOTWALK\n",
    "    NROWS = 3\n",
    "    NCOLS = NFIGS // NROWS\n",
    "    FIGSIZE = (4 * NCOLS, 3 * NROWS)\n",
    "\n",
    "    fig, axs = plt.subplots(ncols=NCOLS, nrows=NROWS, figsize=FIGSIZE)\n",
    "\n",
    "    n = 0\n",
    "    for _, w in data.resample(f\"{WINDOW_SEC}s\"):\n",
    "        if w['annotation'].sum() >= STEPTOL:\n",
    "            plotw(w, axs.flat[n], **kwargs)\n",
    "            n += 1\n",
    "        if n >= NFIGS_WALK: break\n",
    "\n",
    "    m = 0\n",
    "    for _, w in data.resample(f\"{WINDOW_SEC}s\"):\n",
    "        if w['annotation'].sum() < STEPTOL:\n",
    "            plotw(w, axs.flat[n + m], **kwargs)\n",
    "            m += 1\n",
    "        if m >= NFIGS_NOTWALK: break\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visuals\n",
    "\n",
    "Always good idea to visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_csv(oxwalk_dir+\"P01_wrist100.csv\")\n",
    "\n",
    "fig = plotsome(data)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top two rows in these plots are indicitive of times of walking, while the bottom row includes epochs of defined non-walking.\n",
    "In the setup, we've defined walking as at least 4 annotated steps in a 10 second window.\n",
    "How do the plots change when we change our definition of walking (ie. change the number of steps per 10 second epoch required to be classified as walking)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step counts\n",
    "\n",
    "To infer steps from accelerometry, we assume that steps correspond to peaks in acceleration.\n",
    "This is reasonable: You might recall that conundrum in highschool physics about\n",
    "instantaneaous collisions resulting in infinite forces.\n",
    "\n",
    "We will use the peak finding algorithm implemented in `scipy.find_peaks`. \n",
    "\n",
    "Let's visualize the traces again, this time enabling peak finding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plotsome(data, find_peaks=True)\n",
    "fig.suptitle(\"find_peaks=True\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peak finding with default parameters finds every single peak present in the signal, which is not really what we want.\n",
    "\n",
    "We can tune the peak finder to only consider peaks that satisfy certain\n",
    "conditions. Two parameters that we can tune are the minimum `distance` between\n",
    "peaks and the minimum `prominence` of the peaks. The higher these values, the\n",
    "stricter the peak selection becomes.\n",
    "\n",
    "After eyeballing the plots, let's try values 0.1 for `prominence` and 0.2 sec for `distance`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plotsome(\n",
    "    data, \n",
    "    find_peaks=True,\n",
    "    find_peaks_params={\n",
    "        'distance': .2 * SAMPLE_RATE,  # 0.2s in ticks\n",
    "        'prominence': .1\n",
    "    }\n",
    ")\n",
    "fig.suptitle(\"find_peaks=True | dist=.2, promin=.1\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get big improvements after tuning the peak finder.\n",
    "\n",
    "A common signal processing technique is to filter out frequencies that are irrelevant for the task.\n",
    "In activity recognition, a lowpass filter with 3Hz cutoff is commonly applied for walk analysis.\n",
    "\n",
    "Let's apply a 5Hz lowpass filter. We use a looser cutoff as we might also want to capture running steps, for which 5Hz is a reasonable upper bound. \n",
    "For example, Usain Bolt's sprint frequency is around 4.3Hz: https://www.econathletes.com/post/math-for-sprinters-steps-per-second-and-stride-length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plotsome(\n",
    "    data, \n",
    "    find_peaks=True,\n",
    "    find_peaks_params={\n",
    "        'distance': .2 * SAMPLE_RATE,  # 0.2s in ticks\n",
    "        'prominence': .1\n",
    "    },\n",
    "    lp=5,  # 5Hz lowpass filter\n",
    ")\n",
    "fig.suptitle(\"find_peaks=True | dist=.2, promin=.1 | lp=5\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filter clears out the signal making it easier to find relevant peaks. It helps most in reducing false positives, especially when high frequencies are present.\n",
    "\n",
    "While peak finding performs well for walk windows (first two rows), it tends to give false positives in non-walk windows (last row). This motivates us to build a _walk detection model_ to further filter only the walk segments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walk detection model\n",
    "\n",
    "After splitting the data into 10 sec windows, we extract features commonly used in the activity recognition literature. We then train a random forest to classify each window as either walk or non-walk. Finally, a hidden Markov model is applied to \"glue\" together the model outputs in a smooth manner.\n",
    "\n",
    "Note that the model used in Small et al. (2023) [[1]]((https://www.medrxiv.org/content/10.1101/2023.02.20.23285750v1)) was instead a ResNet18, however we demonstrate a random forest in this tutorial. It would be possible to exchange the walking detection model with any supervised learning model, with various benefits and pitfalls.\n",
    "\n",
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_windows(data, window_sec=WINDOW_SEC, sample_rate=SAMPLE_RATE):\n",
    "    \"\"\" Split data into windows, extract features and assign labels \"\"\"\n",
    "\n",
    "    X_raw = []\n",
    "    X_feats = []\n",
    "\n",
    "    window_len = int(window_sec * sample_rate)\n",
    "\n",
    "    for i, w in data.resample(f\"{window_sec}s\"):\n",
    "\n",
    "        if len(w) < window_len:\n",
    "            continue\n",
    "        \n",
    "        if w.isna().any().any():\n",
    "            continue\n",
    "\n",
    "        steps = w['annotation'].sum()\n",
    "        is_walk = int(steps >= STEPTOL)\n",
    "        #steps *= is_walk  # only count if it's a walk window\n",
    "        xyz = w[['x', 'y', 'z']].to_numpy()\n",
    "\n",
    "        X_raw.append(xyz)\n",
    "\n",
    "        X_feats.append({\n",
    "            'time': w.index[0],\n",
    "            **features.extract_features(xyz, sample_rate),\n",
    "            'steps': steps,\n",
    "            'is_walk': is_walk,\n",
    "        })\n",
    "\n",
    "    X_raw = np.stack(X_raw)\n",
    "    X_feats = pd.DataFrame(X_feats)\n",
    "\n",
    "    return X_raw, X_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "feats = []\n",
    "\n",
    "for filename in tqdm(glob(oxwalk_dir+\"*.csv\")):\n",
    "\n",
    "    data = read_csv(filename)\n",
    "    _X_raw, _X_feats = make_windows(data)\n",
    "    pid = re.search(r'(P\\d{2})', os.path.basename(filename)).group(1).upper()  # P01, P02, ...\n",
    "    _X_feats['pid'] = pid\n",
    "\n",
    "    X.append(_X_raw)\n",
    "    feats.append(_X_feats)\n",
    "\n",
    "X = np.concatenate(X)\n",
    "feats = pd.concat(feats)\n",
    "\n",
    "display(feats)\n",
    "print(\"X shape:\", X.shape)\n",
    "\n",
    "# Save for future use\n",
    "np.save(\"X.npy\", X)\n",
    "feats.to_pickle(\"feats.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest for walk detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('X.npy')\n",
    "feats = pd.read_pickle('feats.pkl')\n",
    "\n",
    "# Train/Test split\n",
    "\n",
    "np.random.seed(123)  # for reproducibility\n",
    "\n",
    "test_pids = np.random.choice(feats['pid'].unique(), size=10, replace=False)\n",
    "feats_test = feats[feats['pid'].isin(test_pids)]\n",
    "feats_train = feats[~feats['pid'].isin(test_pids)]\n",
    "\n",
    "print(\"Test PIDs:\", test_pids)\n",
    "print(\"Train frame shape:\", feats_train.shape)\n",
    "print(\"Test frame shape:\", feats_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_feats_cols = ['time', 'pid', 'is_walk', 'steps']\n",
    "\n",
    "X_train = feats_train.drop(columns=not_feats_cols).to_numpy()\n",
    "Y_train = feats_train['is_walk'].to_numpy()\n",
    "pid_train = feats_train['pid'].to_numpy()\n",
    "\n",
    "clf = BalancedRandomForestClassifier(\n",
    "    n_estimators=1000,\n",
    "    replacement=True,\n",
    "    sampling_strategy='not minority',\n",
    "    oob_score=True,\n",
    "    n_jobs=4,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "X_test = feats_test.drop(columns=not_feats_cols).to_numpy()\n",
    "Y_test = feats_test['is_walk'].to_numpy()\n",
    "pid_test = feats_test['pid'].to_numpy()\n",
    "\n",
    "Y_test_pred = clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(Y_test, Y_test_pred))\n",
    "print(\"Per participant F1 score: {}\".format(np.mean([metrics.f1_score(Y_test[pid_test==pid], \n",
    "                                                                      Y_test_pred[pid_test==pid]) \n",
    "                                                     for pid in np.unique(pid_test)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For computational efficiency you may sometimes need to adjust the number of estimators in the model. \n",
    "How does changing the number of estimators affect model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest classifier we are using is a balanced classifier, meaning that it assumes there should be a roughly even distribution between the walk and non-walk classes. \n",
    "Look through the data, is this true in our training data? Is this true in free-living? \n",
    "What are the implications of using a balanced classifier for walking detection trained in this data?\n",
    "\n",
    "If you have time, looking at the [documentation for the balanced random forest](https://imbalanced-learn.org/stable/references/generated/imblearn.ensemble.BalancedRandomForestClassifier.html), how might you address this issue of balance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Markov model\n",
    "\n",
    "The random forest classifies each window independently and doesn't account for\n",
    "temporal dependencies, so we further apply a HMM to smooth the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmms = hmm_utils.HMMSmoother().fit(clf.oob_decision_function_, Y_train, pid_train)\n",
    "Y_test_pred_hmm = hmms.predict(Y_test_pred, pid_test)\n",
    "print(metrics.classification_report(Y_test, Y_test_pred_hmm))\n",
    "print(\"Per participant F1 score: {}\".format(np.mean([metrics.f1_score(Y_test[pid_test==pid], \n",
    "                                                                      Y_test_pred_hmm[pid_test==pid]) \n",
    "                                                     for pid in np.unique(pid_test)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-end model training and testing\n",
    "\n",
    "Combining these concepts together, we can train a single step counter model that will fit both the peak detector, and the walking detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, split into training and test\n",
    "test_pids = np.random.choice(feats['pid'].unique(), size=10, replace=False)\n",
    "\n",
    "X_raw_train = X[~feats['pid'].isin(test_pids)]\n",
    "X_raw_test = X[feats['pid'].isin(test_pids)]\n",
    "Y_train = feats.loc[~feats['pid'].isin(test_pids), 'steps'].to_numpy()\n",
    "Y_test = feats.loc[feats['pid'].isin(test_pids), 'steps'].to_numpy()\n",
    "pid_train = feats.loc[~feats['pid'].isin(test_pids), 'pid'].to_numpy()\n",
    "pid_test = feats.loc[feats['pid'].isin(test_pids), 'pid'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use step counter model to train end-to-end\n",
    "# Note: this can take a long time\n",
    "stepCounter = models.StepCounter(wd_type='rf', window_sec=WINDOW_SEC,\n",
    "                                 sample_rate=SAMPLE_RATE, steptol=STEPTOL,\n",
    "                                 verbose=True)\n",
    "stepCounter.fit(X_raw_train, Y_train, pid_train)\n",
    "\n",
    "# View trained parameters:\n",
    "print(\"Tuned peak parameters: {}\".format(stepCounter.find_peaks_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can also view other trained parameters:\n",
    "* Walk detection training performance: `stepCounter.cv_results[\"walk_detector\"][\"scores\"]`\n",
    "* Step count training performance: `stepCounter.cv_results[\"step_counter\"][\"scores\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the step counter on the test population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_step_pred = []\n",
    "test_step_true = []\n",
    "\n",
    "for pid in np.unique(pid_test):\n",
    "    X_p = X_raw_test[pid_test == pid]\n",
    "    Y_p = Y_test[pid_test == pid]\n",
    "    \n",
    "    test_step_true.append(sum(Y_p))\n",
    "    test_step_pred.append(sum(stepCounter.predict(X_p, Y_p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, step count performance is evaluated using the [mean absolute percentage error (MAPE)](https://en.wikipedia.org/wiki/Mean_absolute_percentage_error).\n",
    "Existing literature surrounding the use of wrist-worn accelerometers requires a step count algorithm to have a MAPE <10% to be considered valid [[1]](https://journals.lww.com/acsm-msse/Fulltext/2018/03000/Validity_of_Wearable_Activity_Monitors_during.28.aspx). \n",
    "This requirement is generally only tested on data collected in controlled environments, on a healthy population. \n",
    "Investigation into many commercial devices show the MAPE to sit around this value, under the previously listed conditions [[2]](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6743766/#pone.0222569.ref036).\n",
    "For this dataset however, we monitor participants during free living, in which walking behaviour is far less typical.\n",
    "\n",
    "We calculate the MAPE for the test population below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean absolute percentage error: {:.2f}%\".format(\n",
    "    100*metrics.mean_absolute_percentage_error(test_step_true, test_step_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, it common to generate a bland altman plot, to visualise how the predicted step count deviates from the true step count. \n",
    "Through this, we can visualise biases in our model, and compare to other step count models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference and the average of the two measurements\n",
    "diff = np.array(test_step_pred) - np.array(test_step_true)\n",
    "mean = np.mean([test_step_pred, test_step_true], axis=0)\n",
    "\n",
    "# Define the limits of agreement as +/- 1.96 times the standard deviation of the differences\n",
    "lim_agree = 1.96 * np.std(diff)\n",
    "\n",
    "# Create the Bland-Altman plot\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "ax.scatter(mean, diff, color='black', s=50)\n",
    "ax.axhline(np.mean(diff), color='gray', linestyle='--', linewidth=1)\n",
    "ax.axhline(np.mean(diff) + lim_agree, color='red', linestyle='--', linewidth=1)\n",
    "ax.axhline(np.mean(diff) - lim_agree, color='red', linestyle='--', linewidth=1)\n",
    "\n",
    "# Set axis labels and title\n",
    "ax.set_xlabel('Average of two measurements')\n",
    "ax.set_ylabel('Difference between two measurements')\n",
    "ax.set_title('Bland-Altman Plot')\n",
    "\n",
    "# Set the x and y axis limits\n",
    "ax.set_xlim([np.min(mean) - 200, np.max(mean) + 200])\n",
    "ax.set_ylim([np.min(diff) - 200, np.max(diff) + 1000])\n",
    "\n",
    "# Add gridlines\n",
    "ax.grid(True)\n",
    "\n",
    "# Add a legend\n",
    "ax.legend(['Mean Difference', 'Limits of Agreement'], loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What other metric could be used to measure the performance of a step counting algorithm? \n",
    "When you implement that below, does it agree with the MAPE performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. [https://www.medrxiv.org/content/10.1101/2023.02.20.23285750v1](https://www.medrxiv.org/content/10.1101/2023.02.20.23285750v1)\n",
    "2. [https://journals.lww.com/acsm-msse/Fulltext/2018/03000/Validity_of_Wearable_Activity_Monitors_during.28.aspx)](https://journals.lww.com/acsm-msse/Fulltext/2018/03000/Validity_of_Wearable_Activity_Monitors_during.28.aspx). \n",
    "3. [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6743766/#pone.0222569.ref036](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6743766/#pone.0222569.ref036)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b165978a2dd9883ce1522b96a38a2ffa9062962723d6d42128fa05e7e8942e0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
